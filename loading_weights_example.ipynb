{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('energy_vector',\n",
       "              tensor([[[-0.3652, -0.4663, -0.4409, -0.5159, -0.3000, -0.1640,  0.0396,\n",
       "                        -0.0046,  0.0875, -0.3347],\n",
       "                       [ 0.3652,  0.4663,  0.4409,  0.5159,  0.3000,  0.1640, -0.0396,\n",
       "                         0.0046, -0.0875,  0.3347]],\n",
       "              \n",
       "                      [[-0.2893, -0.5098, -0.3838, -0.4227, -0.3012, -0.3415, -0.1468,\n",
       "                        -0.1169, -0.1215, -0.3729],\n",
       "                       [ 0.2893,  0.5098,  0.3838,  0.4227,  0.3012,  0.3415,  0.1468,\n",
       "                         0.1169,  0.1215,  0.3729]],\n",
       "              \n",
       "                      [[-0.4133, -0.5344, -0.5600, -0.4911, -0.3714, -0.2711, -0.2683,\n",
       "                        -0.2164,  0.0027, -0.3472],\n",
       "                       [ 0.4133,  0.5344,  0.5600,  0.4911,  0.3714,  0.2711,  0.2683,\n",
       "                         0.2164, -0.0027,  0.3472]],\n",
       "              \n",
       "                      [[-0.4157, -0.5086, -0.5342, -0.5445, -0.3857, -0.3250, -0.4351,\n",
       "                        -0.3208, -0.1769, -0.4604],\n",
       "                       [ 0.4157,  0.5086,  0.5342,  0.5445,  0.3857,  0.3250,  0.4351,\n",
       "                         0.3208,  0.1769,  0.4604]],\n",
       "              \n",
       "                      [[-0.3758, -0.4292, -0.3531, -0.4329, -0.2543, -0.2697, -0.2929,\n",
       "                        -0.2322, -0.3030, -0.4924],\n",
       "                       [ 0.3758,  0.4292,  0.3531,  0.4329,  0.2543,  0.2697,  0.2929,\n",
       "                         0.2322,  0.3030,  0.4924]],\n",
       "              \n",
       "                      [[-0.3132, -0.4385, -0.3921, -0.4098, -0.3004, -0.3718, -0.1786,\n",
       "                        -0.1002, -0.1494, -0.3873],\n",
       "                       [ 0.3132,  0.4385,  0.3921,  0.4098,  0.3004,  0.3718,  0.1786,\n",
       "                         0.1002,  0.1494,  0.3873]]])),\n",
       "             ('source_response',\n",
       "              tensor([ 0.0912,  0.0757,  0.0530,  ..., -0.0341, -0.1329, -0.0703])),\n",
       "             ('directivity_sphere',\n",
       "              tensor([[0.8072, 0.5312, 0.7795,  ..., 0.9333, 0.9919, 0.6564],\n",
       "                      [0.8057, 0.5364, 0.7348,  ..., 0.8378, 0.9346, 0.6467],\n",
       "                      [0.7968, 0.5402, 0.8078,  ..., 0.9379, 0.9934, 0.6511],\n",
       "                      ...,\n",
       "                      [0.5772, 0.6070, 0.7037,  ..., 0.7727, 0.8545, 0.6276],\n",
       "                      [0.5995, 0.5956, 0.6395,  ..., 0.8224, 0.8342, 0.6537],\n",
       "                      [0.5924, 0.6037, 0.6631,  ..., 0.7900, 0.8333, 0.6641]])),\n",
       "             ('decay', tensor([4.7704])),\n",
       "             ('RIR_residual',\n",
       "              tensor([ 0.0000e+00, -8.0037e-03,  8.4589e-03,  ..., -1.0176e-04,\n",
       "                      -4.6555e-05, -9.5468e-05])),\n",
       "             ('spline_values',\n",
       "              tensor([-4.2044, -3.9225, -4.0867, -3.3843, -3.0853, -2.9088, -2.9768, -3.2648,\n",
       "                      -2.7226, -3.0500, -2.7532, -2.4338, -1.9918, -0.9606, -0.0437,  0.2916,\n",
       "                       0.5230,  0.9110,  0.4990,  1.2634,  1.5919,  1.8620,  2.1397,  2.3796,\n",
       "                       2.6492,  3.0589,  3.4697,  3.0509,  3.5037,  3.8132,  4.2818,  4.2243,\n",
       "                       4.4209,  4.7026])),\n",
       "             ('bp_ord_cut_freqs',\n",
       "              tensor([  70.,  400.,  800., 1000., 1300., 2000.]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = np.load('/home/gzanin/Desktop/hearinganythinganywhere/~/prova_training_1000epochs/weights.pt', allow_pickle = True)\n",
    "\n",
    "data = torch.load('/home/gzanin/Desktop/hearinganythinganywhere/~/prova_training_1000epochs/weights.pt', map_location=torch.device('cpu'))\n",
    "data['model_state_dict']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.2044, -3.9225, -4.0867, -3.3843, -3.0853, -2.9088, -2.9768, -3.2648,\n",
       "        -2.7226, -3.0500, -2.7532, -2.4338, -1.9918, -0.9606, -0.0437,  0.2916,\n",
       "         0.5230,  0.9110,  0.4990,  1.2634,  1.5919,  1.8620,  2.1397,  2.3796,\n",
       "         2.6492,  3.0589,  3.4697,  3.0509,  3.5037,  3.8132,  4.2818,  4.2243,\n",
       "         4.4209,  4.7026])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['model_state_dict']['spline_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = torch.load('/home/gzanin/Desktop/hearinganythinganywhere/models/hallwayBase/weights.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "#print(model_weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1889,  0.9600,  0.1497, -1.6674, -1.7362, -0.8662, -0.0920, -0.1603,\n",
       "        -0.7774, -0.5799, -0.2962, -0.4480, -0.3558, -0.4179, -0.6262, -0.7645,\n",
       "        -0.8553, -0.9175, -1.0549, -1.1494, -1.2660, -1.3254, -1.3975, -1.4152,\n",
       "        -1.5259, -1.5676, -1.6296, -1.7462, -1.7349, -1.8844, -2.0238, -2.2500,\n",
       "        -2.5868, -2.5822])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights['model_state_dict']['spline_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_losses = np.load('/home/gzanin/Desktop/hearinganythinganywhere/~/prova_training_1000epochs/losses.npy')\n",
    "data_losses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_losses = np.load('/home/gzanin/Desktop/prova_training_2epochs/losses.npy')\n",
    "data_losses.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dummy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_directional_list_for_beampattern(angular_sensitivity, n_freq_samples, device):\n",
    "\n",
    "    frequency_responses_list = []\n",
    "    used_angle = 180/(int(180/angular_sensitivity))\n",
    "    azimuths = np.arange(0, 360, used_angle)\n",
    "    elevations = np.arange(-90, 90+ used_angle, used_angle)\n",
    "    for elevation in elevations:\n",
    "        if (elevation == -90 or elevation == 90):\n",
    "            direction_dict = dict()\n",
    "            direction_dict['angle'] = [0, elevation]#-90 and +90 elevations are considered having azimuth=0\n",
    "            direction_dict['f_response'] = torch.zeros(n_freq_samples).to(device)\n",
    "            frequency_responses_list.append(direction_dict)\n",
    "        else:   \n",
    "            for azimuth in azimuths:\n",
    "                direction_dict = dict()\n",
    "                direction_dict['angle'] = [azimuth, elevation]\n",
    "                direction_dict['f_response'] = torch.zeros(n_freq_samples).to(device)\n",
    "                frequency_responses_list.append(direction_dict)\n",
    "\n",
    "    return frequency_responses_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########CONSIDERO CHE SOLO I PRIMI 12 MICROFONI SONO CAMERE ACUSTICHE 3D\n",
    "\n",
    "m = []\n",
    "\n",
    "for i in range (12):\n",
    "    m.append(initialize_directional_list_for_beampattern(60, 1, \"cpu\"))\n",
    "\n",
    "for j in range (len(m)):\n",
    "    for r in m[j]:\n",
    "        r['t_response'] = data[j]\n",
    "\n",
    "m = np.array(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "m= data[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/gzanin/Desktop/prova_dataset/xyzs.npy', m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.4241125 , 0.581025  , 0.32      ],\n",
       "       [2.16535   , 0.581025  , 0.32      ],\n",
       "       [1.90738125, 0.581025  , 0.32      ],\n",
       "       [1.6430625 , 0.581025  , 0.32      ],\n",
       "       [1.38826875, 0.581025  , 0.32      ],\n",
       "       [1.12633125, 0.581025  , 0.32      ],\n",
       "       [0.866775  , 0.581025  , 0.32      ],\n",
       "       [2.4241125 , 0.955675  , 0.32      ],\n",
       "       [2.16535   , 0.955675  , 0.32      ],\n",
       "       [1.90738125, 0.955675  , 0.32      ],\n",
       "       [1.6430625 , 0.955675  , 0.32      ],\n",
       "       [1.38826875, 0.955675  , 0.32      ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = np.load('/home/gzanin/Desktop/prova_dataset/xyzs.npy', allow_pickle=True, encoding= 'latin1')\n",
    "\n",
    "new_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
