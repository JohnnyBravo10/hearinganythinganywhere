{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rooms.dataset\n",
    "import render\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import metrics\n",
    "import train\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"prova\"\n",
    "\n",
    "D = rooms.dataset.dataLoader(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training parameters\n",
    "\n",
    "n_fibonacci = 128 #128\n",
    "late_stage_model= \"UniformResidual\" #\"UniformResidual\"\n",
    "toa_perturb = True #True\n",
    "model_transmission = False #False\n",
    "\n",
    "skip_train = False #False\n",
    "continue_train = False #False\n",
    "\n",
    "n_epochs = 1 #1000\n",
    "batch_size = 4 #4\n",
    "lr = 1e-2 #1e-2\n",
    "pink_noise_supervision = False #True\n",
    "pink_start_epoch = 500 #500\n",
    "fs = 48000 #48000\n",
    "\n",
    "load_dir= None\n",
    "save_dir= '~/prova_training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = render.Renderer(n_surfaces=len(D.all_surfaces), n_fibonacci=n_fibonacci,\n",
    "                        late_stage_model=late_stage_model,\n",
    "                        toa_perturb = toa_perturb, model_transmission=model_transmission).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizza piÃ¹ GPU se disponibili\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    R = nn.DataParallel(R).module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solo per training le prossime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directional case\n",
    "loss_fcn = metrics.training_loss_for_learned_bp\n",
    "\n",
    "for listener_position in D.RIRs:\n",
    "    for response in listener_position:\n",
    "        response['t_response'] = torch.Tensor(response['t_response'][:R.RIR_length])\n",
    "        response['t_response'].to(device) \n",
    "\n",
    "gt_audio = D.RIRs\n",
    "rendering_method = render.Renderer.render_RIR_learned_beampattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(indices, source_xyz, listener_xyzs, surfaces, load_dir):\n",
    "    Ls = []\n",
    "\n",
    "    for idx in indices:\n",
    "        L= render.get_listener(source_xyz=source_xyz, listener_xyz = listener_xyzs[idx], surfaces = surfaces, \n",
    "                               load_dir = load_dir, load_num = idx, speed_of_sound = D.speed_of_sound, \n",
    "                               max_order = D.max_order, parallel_surface_pairs = D.parallel_surface_pairs, \n",
    "                               max_axial_order = D.max_axial_order)\n",
    "        Ls.append(L)\n",
    "    return Ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "if not skip_train:\n",
    "    print(\"Training\")\n",
    "\n",
    "    #Initialize Listeners\n",
    "    Ls = initialize(indices=D.train_indices,\n",
    "                    listener_xyzs=D.xyzs,\n",
    "                    source_xyz=D.speaker_xyz,\n",
    "                    surfaces=D.all_surfaces,\n",
    "                    load_dir=load_dir)\n",
    "            \n",
    "    if continue_train:\n",
    "        R.load_state_dict(torch.load(os.path.join(save_dir,\"weights.pt\"))['model_state_dict'])\n",
    "\n",
    "    losses = train.train_loop(R=R, Ls=Ls, train_gt_audio=gt_audio[D.train_indices], D=D,\n",
    "                        n_epochs = n_epochs, batch_size = batch_size, lr = lr, loss_fcn = loss_fcn,\n",
    "                        save_dir=save_dir,\n",
    "                        pink_noise_supervision = pink_noise_supervision,\n",
    "                        pink_start_epoch=pink_start_epoch,\n",
    "                        continue_train = continue_train, fs=fs)\n",
    "\n",
    "else:\n",
    "    R.load_state_dict(torch.load(os.path.join(save_dir,\"weights.pt\"))['model_state_dict'])\n",
    "    R.train = False\n",
    "    R.toa_perturb = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prova di ascolto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_file = torch.load(save_dir + '/weights.pt', map_location=device)\n",
    "R.energy_vector = nn.Parameter(pt_file['model_state_dict']['energy_vector'])\n",
    "R.source_response = nn.Parameter(pt_file['model_state_dict']['source_response'])\n",
    "R.directivity_sphere = nn.Parameter(pt_file['model_state_dict']['directivity_sphere'])\n",
    "R.decay = nn.Parameter(pt_file['model_state_dict']['decay'])\n",
    "R.RIR_residual = nn.Parameter(pt_file['model_state_dict']['RIR_residual'])\n",
    "R.spline_values = nn.Parameter(pt_file['model_state_dict']['spline_values'])\n",
    "\n",
    "R.bp_ord_cut_freqs = nn.Parameter(pt_file['model_state_dict']['bp_ord_cut_freqs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considered Paths:\t6\n",
      "Total Considered Paths, after Axial:\t6\n",
      "Valid Paths:\t7\n"
     ]
    }
   ],
   "source": [
    "listener = render.get_listener(source_xyz= np.array([5,8,1.5]), listener_xyz = np.array([5,9,1.5]), surfaces = D.all_surfaces, \n",
    "                               load_dir = load_dir, load_num = None, speed_of_sound = D.speed_of_sound, \n",
    "                               max_order = D.max_order, parallel_surface_pairs = D.parallel_surface_pairs, \n",
    "                               max_axial_order = D.max_axial_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4154e-09,  2.0472e-09, -3.1614e-08,  ..., -1.1770e-04,\n",
       "        -7.3632e-05, -1.1808e-04], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RIR = R.render_RIR(listener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 480000)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_music = evaluate.render_music(np.array([RIR.detach().cpu()]), np.array([D.music_dls[0]]), device = device)\n",
    "predicted_music.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1, 624000)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.music_dls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sounddevice as sd\n",
    "\n",
    "#duration = predicted_music.shape[2]/fs  # Durata in secondi\n",
    "#t = np.linspace(0, duration, int(fs * duration), endpoint=False)\n",
    "\n",
    "\n",
    "#sd.play(predicted_music[0][0], samplerate=48000)\n",
    "#sd.wait()  # Aspetta che la riproduzione termini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sd\u001b[38;5;241m.\u001b[39mplay(D\u001b[38;5;241m.\u001b[39mmusic_dls[\u001b[38;5;241m9\u001b[39m][\u001b[38;5;241m0\u001b[39m], samplerate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m48000\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Aspetta che la riproduzione termini\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sounddevice.py:395\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(ignore_errors)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for `play()`/`rec()`/`playrec()` to be finished.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03mPlayback/recording can be stopped with a `KeyboardInterrupt`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m \n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _last_callback:\n\u001b[0;32m--> 395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sounddevice.py:2624\u001b[0m, in \u001b[0;36m_CallbackContext.wait\u001b[0;34m(self, ignore_errors)\u001b[0m\n\u001b[1;32m   2618\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for finished_callback.\u001b[39;00m\n\u001b[1;32m   2619\u001b[0m \n\u001b[1;32m   2620\u001b[0m \u001b[38;5;124;03mCan be interrupted with a KeyboardInterrupt.\u001b[39;00m\n\u001b[1;32m   2621\u001b[0m \n\u001b[1;32m   2622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2623\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2624\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2625\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mclose(ignore_errors)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#sd.play(D.music_dls[9][0], samplerate=48000)\n",
    "#sd.wait()  # Aspetta che la riproduzione termini"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
