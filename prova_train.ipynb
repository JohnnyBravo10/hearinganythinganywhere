{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gzanin/.local/lib/python3.11/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import rooms.dataset\n",
    "import render_optimized as render\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import metrics\n",
    "import train\n",
    "import os\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import trace1\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"classroomBase\"\n",
    "\n",
    "D = rooms.dataset.dataLoader(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training parameters\n",
    "\n",
    "n_fibonacci = 128 #128 \n",
    "late_stage_model= \"UniformResidual\" #\"UniformResidual\"\n",
    "toa_perturb = True #True\n",
    "model_transmission = False #False\n",
    "\n",
    "skip_train = False #False\n",
    "continue_train = False #False\n",
    "\n",
    "n_epochs = 3 #1000 \n",
    "batch_size = 4 #4 #4 nel test\n",
    "lr = 1e-2 #1e-2\n",
    "pink_noise_supervision = True #True\n",
    "pink_start_epoch = 2 #500\n",
    "fs = 48000 #48000 \n",
    "\n",
    "load_dir= 'precomputed/' + dataset_name\n",
    "save_dir= '~/prova_different'\n",
    "\n",
    "skip_inference = False #False\n",
    "skip_music = False #False\n",
    "skip_eval = False #False\n",
    "skip_binaural = False #False\n",
    "\n",
    "valid = False #False #Evaluate on valid instead of test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = render.Renderer(n_surfaces=len(D.all_surfaces), n_fibonacci=n_fibonacci,\n",
    "                        late_stage_model=late_stage_model,\n",
    "                        toa_perturb = toa_perturb, model_transmission=model_transmission).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use multiple GPUs if available\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    R = nn.DataParallel(R).module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omnidirectional case\n",
    "\n",
    "#loss_fcn = metrics.training_loss\n",
    "\n",
    "gt_audio = torch.Tensor(D.RIRs[:, :R.RIR_length])\n",
    "\n",
    "#rendering_method = render.Renderer.render_RIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nloss_fcn = metrics.training_loss_directional\\n#loss_fcn = metrics.training_loss_directional_with_decay\\n\\nfor listener_position in D.RIRs:\\n    for response in listener_position:\\n        response['t_response'] = torch.Tensor(response['t_response'][:R.RIR_length])\\n        response['t_response'].to(device) \\n\\ngt_audio = D.RIRs\\nrendering_method = render.Renderer.render_RIR_directional\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directional case\n",
    "'''\n",
    "loss_fcn = metrics.training_loss_directional\n",
    "#loss_fcn = metrics.training_loss_directional_with_decay\n",
    "\n",
    "for listener_position in D.RIRs:\n",
    "    for response in listener_position:\n",
    "        response['t_response'] = torch.Tensor(response['t_response'][:R.RIR_length])\n",
    "        response['t_response'].to(device) \n",
    "\n",
    "gt_audio = D.RIRs\n",
    "rendering_method = render.Renderer.render_RIR_directional\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solo per training le prossime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn = metrics.training_loss\n",
    "gt_audio = torch.Tensor(D.RIRs[:, :R.RIR_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(indices, source_xyz, listener_xyzs, surfaces, load_dir,\n",
    "               ######################################################\n",
    "                rendering_methods,\n",
    "                mic_orientations,\n",
    "                mic_0_gains,\n",
    "                mic_180_loss,\n",
    "                cardioid_exponents):\n",
    "    Ls = []\n",
    "\n",
    "    for idx in indices:\n",
    "        L= render.get_listener(source_xyz=source_xyz, listener_xyz = listener_xyzs[idx], surfaces = surfaces, \n",
    "                               load_dir = load_dir, load_num = idx, speed_of_sound = D.speed_of_sound, \n",
    "                               max_order = D.max_order, parallel_surface_pairs = D.parallel_surface_pairs, \n",
    "                               max_axial_order = D.max_axial_order, \n",
    "                               ####################################################\n",
    "                               rendering_method = rendering_methods[idx], mic_orientation = mic_orientations[idx], mic_0_gains = mic_0_gains[idx], mic_180_loss = mic_180_loss[idx], cardioid_exponents = cardioid_exponents[idx])\n",
    "        Ls.append(L)\n",
    "    return Ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Listener Loading From: precomputed/classroomBase\n",
      "Listener Loading From: precomputed/classroomBase\n",
      "Listener Loading From: precomputed/classroomBase\n",
      "Listener Loading From: precomputed/classroomBase\n",
      "Listener Loading From: precomputed/classroomBase\n",
      "Listener Loading From: precomputed/classroomBase\n",
      "Listener Loading From: precomputed/classroomBase\n",
      "Listener Loading From: precomputed/classroomBase\n",
      "Listener Loading From: precomputed/classroomBase\n",
      "Listener Loading From: precomputed/classroomBase\n",
      "Listener Loading From: precomputed/classroomBase\n",
      "Listener Loading From: precomputed/classroomBase\n",
      "Loss:\t<function training_loss at 0x795b848b7a60>\n",
      "Late Network Style\tUniformResidual\n",
      "energy_vector\n",
      "source_response\n",
      "directivity_sphere\n",
      "decay\n",
      "RIR_residual\n",
      "spline_values\n",
      "bp_ord_cut_freqs\n",
      "training initialized\n",
      "Epoch n°:\n",
      "0\n",
      "iteration number: 0 of 3\n",
      "Omnidirectional case\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gzanin/.local/lib/python3.11/site-packages/torch/functional.py:665: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "1.871401538387813\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "1.6708176620814816\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "2.2123343049491027\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "1.9546340958831296\n",
      "parameters\n",
      "tensor([[[ 0.0100,  0.0100,  0.0100,  0.0100,  0.0100,  0.0100,  0.0100,\n",
      "           0.0100,  0.0100, -0.0100],\n",
      "         [-0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100,\n",
      "          -0.0100, -0.0100,  0.0100]],\n",
      "\n",
      "        [[ 0.0100,  0.0100,  0.0100,  0.0100,  0.0100,  0.0100,  0.0100,\n",
      "           0.0100,  0.0100, -0.0100],\n",
      "         [-0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100,\n",
      "          -0.0100, -0.0100,  0.0100]],\n",
      "\n",
      "        [[-0.0100, -0.0100,  0.0100,  0.0100, -0.0100, -0.0100, -0.0100,\n",
      "          -0.0100, -0.0100, -0.0100],\n",
      "         [ 0.0100,  0.0100, -0.0100, -0.0100,  0.0100,  0.0100,  0.0100,\n",
      "           0.0100,  0.0100,  0.0100]],\n",
      "\n",
      "        [[-0.0100, -0.0100,  0.0100,  0.0100, -0.0100, -0.0100, -0.0100,\n",
      "          -0.0100, -0.0100, -0.0100],\n",
      "         [ 0.0100,  0.0100, -0.0100, -0.0100,  0.0100,  0.0100,  0.0100,\n",
      "           0.0100,  0.0100,  0.0100]],\n",
      "\n",
      "        [[ 0.0100,  0.0100,  0.0100,  0.0100,  0.0100,  0.0100,  0.0100,\n",
      "           0.0100,  0.0100, -0.0100],\n",
      "         [-0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100,\n",
      "          -0.0100, -0.0100,  0.0100]],\n",
      "\n",
      "        [[ 0.0100,  0.0100,  0.0100,  0.0100,  0.0100,  0.0100,  0.0100,\n",
      "           0.0100,  0.0100, -0.0100],\n",
      "         [-0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100,\n",
      "          -0.0100, -0.0100,  0.0100]],\n",
      "\n",
      "        [[-0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100,\n",
      "          -0.0100, -0.0100, -0.0100],\n",
      "         [ 0.0100,  0.0100,  0.0100,  0.0100,  0.0100,  0.0100,  0.0100,\n",
      "           0.0100,  0.0100,  0.0100]],\n",
      "\n",
      "        [[-0.0100, -0.0100, -0.0100, -0.0100,  0.0100,  0.0100, -0.0100,\n",
      "          -0.0100, -0.0100, -0.0100],\n",
      "         [ 0.0100,  0.0100,  0.0100,  0.0100, -0.0100, -0.0100,  0.0100,\n",
      "           0.0100,  0.0100,  0.0100]],\n",
      "\n",
      "        [[-0.0100, -0.0100, -0.0100,  0.0100,  0.0100, -0.0100, -0.0100,\n",
      "          -0.0100, -0.0100, -0.0100],\n",
      "         [ 0.0100,  0.0100,  0.0100, -0.0100, -0.0100,  0.0100,  0.0100,\n",
      "           0.0100,  0.0100,  0.0100]]])\n",
      "parameters\n",
      "tensor([ 0.0900,  0.0100, -0.0100,  ..., -0.0100, -0.0100, -0.0100])\n",
      "parameters\n",
      "tensor([[1.0100, 1.0100, 1.0100,  ..., 1.0100, 1.0100, 0.9900],\n",
      "        [1.0100, 1.0100, 1.0100,  ..., 1.0100, 1.0100, 0.9900],\n",
      "        [1.0100, 0.9900, 1.0100,  ..., 1.0100, 1.0100, 0.9900],\n",
      "        ...,\n",
      "        [1.0100, 1.0100, 1.0100,  ..., 1.0100, 1.0100, 0.9900],\n",
      "        [1.0100, 1.0100, 1.0100,  ..., 1.0100, 1.0100, 0.9900],\n",
      "        [1.0100, 1.0100, 1.0100,  ..., 1.0100, 1.0100, 0.9900]])\n",
      "parameters\n",
      "tensor([5.0100])\n",
      "parameters\n",
      "tensor([ 0.0000e+00,  9.9617e-05, -9.9414e-05,  ..., -6.0897e-05,\n",
      "        -6.7891e-05,  8.4564e-05])\n",
      "parameters\n",
      "tensor([-5.0100, -4.6870, -4.3839, -4.0809, -3.7779, -3.4748, -3.1718, -2.8888,\n",
      "        -2.5858, -2.2827, -1.9797, -1.6767, -1.3736, -1.0706, -0.7676, -0.4618,\n",
      "        -0.1515,  0.1515,  0.4545,  0.7576,  1.0606,  1.3636,  1.6667,  1.9697,\n",
      "         2.2727,  2.5758,  2.8788,  3.1818,  3.4848,  3.7879,  4.0909,  4.3939,\n",
      "         4.6970,  5.0000])\n",
      "parameters\n",
      "tensor([  70.,  400.,  800., 1000., 1300., 2000.])\n",
      "optimizer.step() eseguito\n",
      "iteration number: 1 of 3\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.6972100309291394\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.8736355701100527\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "4.18602021188106\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.7491480472512513\n",
      "parameters\n",
      "tensor([[[ 0.0128,  0.0180,  0.0196,  0.0195,  0.0195,  0.0175,  0.0187,\n",
      "           0.0194,  0.0190, -0.0190],\n",
      "         [-0.0128, -0.0180, -0.0196, -0.0195, -0.0195, -0.0175, -0.0187,\n",
      "          -0.0194, -0.0190,  0.0190]],\n",
      "\n",
      "        [[ 0.0143,  0.0181,  0.0200,  0.0200,  0.0198,  0.0175,  0.0189,\n",
      "           0.0191,  0.0194, -0.0192],\n",
      "         [-0.0143, -0.0181, -0.0200, -0.0200, -0.0198, -0.0175, -0.0189,\n",
      "          -0.0191, -0.0194,  0.0192]],\n",
      "\n",
      "        [[-0.0186, -0.0186,  0.0035,  0.0032, -0.0177, -0.0183, -0.0191,\n",
      "          -0.0193, -0.0185, -0.0199],\n",
      "         [ 0.0186,  0.0186, -0.0035, -0.0032,  0.0177,  0.0183,  0.0191,\n",
      "           0.0193,  0.0185,  0.0199]],\n",
      "\n",
      "        [[-0.0190, -0.0186,  0.0034,  0.0029, -0.0176, -0.0190, -0.0193,\n",
      "          -0.0191, -0.0183, -0.0199],\n",
      "         [ 0.0190,  0.0186, -0.0034, -0.0029,  0.0176,  0.0190,  0.0193,\n",
      "           0.0191,  0.0183,  0.0199]],\n",
      "\n",
      "        [[ 0.0087,  0.0067,  0.0146,  0.0159,  0.0153,  0.0119,  0.0157,\n",
      "           0.0189,  0.0172, -0.0192],\n",
      "         [-0.0087, -0.0067, -0.0146, -0.0159, -0.0153, -0.0119, -0.0157,\n",
      "          -0.0189, -0.0172,  0.0192]],\n",
      "\n",
      "        [[ 0.0076,  0.0043,  0.0089,  0.0139,  0.0177,  0.0141,  0.0146,\n",
      "           0.0181,  0.0169, -0.0194],\n",
      "         [-0.0076, -0.0043, -0.0089, -0.0139, -0.0177, -0.0141, -0.0146,\n",
      "          -0.0181, -0.0169,  0.0194]],\n",
      "\n",
      "        [[-0.0175, -0.0181, -0.0197, -0.0178, -0.0176, -0.0175, -0.0187,\n",
      "          -0.0180, -0.0178, -0.0182],\n",
      "         [ 0.0175,  0.0181,  0.0197,  0.0178,  0.0176,  0.0175,  0.0187,\n",
      "           0.0180,  0.0178,  0.0182]],\n",
      "\n",
      "        [[-0.0197, -0.0199, -0.0200, -0.0197,  0.0194,  0.0037, -0.0194,\n",
      "          -0.0178, -0.0188, -0.0200],\n",
      "         [ 0.0197,  0.0199,  0.0200,  0.0197, -0.0194, -0.0037,  0.0194,\n",
      "           0.0178,  0.0188,  0.0200]],\n",
      "\n",
      "        [[-0.0194, -0.0190, -0.0179,  0.0066,  0.0029, -0.0195, -0.0195,\n",
      "          -0.0194, -0.0186, -0.0199],\n",
      "         [ 0.0194,  0.0190,  0.0179, -0.0066, -0.0029,  0.0195,  0.0195,\n",
      "           0.0194,  0.0186,  0.0199]]])\n",
      "parameters\n",
      "tensor([ 0.0813,  0.0170, -0.0170,  ..., -0.0161, -0.0166, -0.0077])\n",
      "parameters\n",
      "tensor([[1.0094, 1.0045, 1.0078,  ..., 1.0142, 1.0162, 0.9803],\n",
      "        [1.0073, 1.0059, 1.0095,  ..., 1.0135, 1.0155, 0.9803],\n",
      "        [1.0031, 0.9821, 1.0053,  ..., 1.0120, 1.0146, 0.9803],\n",
      "        ...,\n",
      "        [1.0092, 1.0189, 1.0199,  ..., 1.0155, 1.0151, 0.9812],\n",
      "        [1.0100, 1.0196, 1.0198,  ..., 1.0143, 1.0137, 0.9814],\n",
      "        [1.0109, 1.0196, 1.0199,  ..., 1.0157, 1.0151, 0.9813]])\n",
      "parameters\n",
      "tensor([5.0032])\n",
      "parameters\n",
      "tensor([ 0.0000e+00,  5.1196e-05, -1.9214e-04,  ...,  1.3516e-05,\n",
      "         6.5223e-06,  1.0150e-05])\n",
      "parameters\n",
      "tensor([-5.0055, -4.6790, -4.3741, -4.0711, -3.7689, -3.4667, -3.1639, -2.8824,\n",
      "        -2.5802, -2.2831, -1.9873, -1.6866, -1.3834, -1.0796, -0.7752, -0.4692,\n",
      "        -0.1590,  0.1441,  0.4471,  0.7501,  1.0532,  1.3562,  1.6592,  1.9623,\n",
      "         2.2653,  2.5683,  2.8713,  3.1744,  3.4774,  3.7804,  4.0835,  4.3865,\n",
      "         4.6895,  4.9926])\n",
      "parameters\n",
      "tensor([  70.,  400.,  800., 1000., 1300., 2000.])\n",
      "optimizer.step() eseguito\n",
      "iteration number: 2 of 3\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.4507954715895064\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.7264683305401127\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.613940013281214\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.4258675212199527\n",
      "parameters\n",
      "tensor([[[ 0.0151,  0.0266,  0.0294,  0.0292,  0.0287,  0.0253,  0.0268,\n",
      "           0.0288,  0.0281, -0.0285],\n",
      "         [-0.0151, -0.0266, -0.0294, -0.0292, -0.0287, -0.0253, -0.0268,\n",
      "          -0.0288, -0.0281,  0.0285]],\n",
      "\n",
      "        [[ 0.0203,  0.0254,  0.0275,  0.0300,  0.0285,  0.0239,  0.0264,\n",
      "           0.0280,  0.0284, -0.0288],\n",
      "         [-0.0203, -0.0254, -0.0275, -0.0300, -0.0285, -0.0239, -0.0264,\n",
      "          -0.0280, -0.0284,  0.0288]],\n",
      "\n",
      "        [[-0.0269, -0.0277, -0.0044, -0.0050, -0.0262, -0.0273, -0.0286,\n",
      "          -0.0288, -0.0276, -0.0298],\n",
      "         [ 0.0269,  0.0277,  0.0044,  0.0050,  0.0262,  0.0273,  0.0286,\n",
      "           0.0288,  0.0276,  0.0298]],\n",
      "\n",
      "        [[-0.0274, -0.0278, -0.0039, -0.0054, -0.0263, -0.0282, -0.0287,\n",
      "          -0.0284, -0.0274, -0.0299],\n",
      "         [ 0.0274,  0.0278,  0.0039,  0.0054,  0.0263,  0.0282,  0.0287,\n",
      "           0.0284,  0.0274,  0.0299]],\n",
      "\n",
      "        [[ 0.0088,  0.0002,  0.0108,  0.0219,  0.0167,  0.0102,  0.0185,\n",
      "           0.0241,  0.0218, -0.0288],\n",
      "         [-0.0088, -0.0002, -0.0108, -0.0219, -0.0167, -0.0102, -0.0185,\n",
      "          -0.0241, -0.0218,  0.0288]],\n",
      "\n",
      "        [[ 0.0043, -0.0034,  0.0026,  0.0147,  0.0228,  0.0141,  0.0154,\n",
      "           0.0228,  0.0219, -0.0291],\n",
      "         [-0.0043,  0.0034, -0.0026, -0.0147, -0.0228, -0.0141, -0.0154,\n",
      "          -0.0228, -0.0219,  0.0291]],\n",
      "\n",
      "        [[-0.0246, -0.0267, -0.0293, -0.0242, -0.0237, -0.0253, -0.0265,\n",
      "          -0.0262, -0.0254, -0.0260],\n",
      "         [ 0.0246,  0.0267,  0.0293,  0.0242,  0.0237,  0.0253,  0.0265,\n",
      "           0.0262,  0.0254,  0.0260]],\n",
      "\n",
      "        [[-0.0287, -0.0294, -0.0296, -0.0271,  0.0156, -0.0039, -0.0275,\n",
      "          -0.0265, -0.0282, -0.0284],\n",
      "         [ 0.0287,  0.0294,  0.0296,  0.0271, -0.0156,  0.0039,  0.0275,\n",
      "           0.0265,  0.0282,  0.0284]],\n",
      "\n",
      "        [[-0.0263, -0.0273, -0.0256, -0.0002, -0.0056, -0.0292, -0.0292,\n",
      "          -0.0286, -0.0276, -0.0297],\n",
      "         [ 0.0263,  0.0273,  0.0256,  0.0002,  0.0056,  0.0292,  0.0292,\n",
      "           0.0286,  0.0276,  0.0297]]])\n",
      "parameters\n",
      "tensor([ 0.0723,  0.0227, -0.0219,  ..., -0.0190, -0.0190, -0.0082])\n",
      "parameters\n",
      "tensor([[1.0087, 0.9972, 1.0026,  ..., 1.0188, 1.0196, 0.9705],\n",
      "        [1.0081, 0.9999, 1.0058,  ..., 1.0178, 1.0190, 0.9705],\n",
      "        [0.9949, 0.9733, 0.9981,  ..., 1.0127, 1.0138, 0.9704],\n",
      "        ...,\n",
      "        [1.0055, 1.0250, 1.0279,  ..., 1.0192, 1.0182, 0.9719],\n",
      "        [1.0072, 1.0267, 1.0285,  ..., 1.0170, 1.0161, 0.9723],\n",
      "        [1.0086, 1.0270, 1.0286,  ..., 1.0202, 1.0189, 0.9722]])\n",
      "parameters\n",
      "tensor([4.9949])\n",
      "parameters\n",
      "tensor([ 0.0000e+00,  4.7455e-06, -2.8750e-04,  ...,  3.8793e-05,\n",
      "         6.4893e-05, -2.7163e-05])\n",
      "parameters\n",
      "tensor([-4.9986, -4.6708, -4.3642, -4.0612, -3.7595, -3.4578, -3.1551, -2.8745,\n",
      "        -2.5726, -2.2783, -1.9957, -1.6961, -1.3932, -1.0772, -0.7706, -0.4711,\n",
      "        -0.1669,  0.1359,  0.4386,  0.7415,  1.0446,  1.3481,  1.6513,  1.9537,\n",
      "         2.2567,  2.5600,  2.8628,  3.1660,  3.4688,  3.7720,  4.0752,  4.3780,\n",
      "         4.6811,  4.9840])\n",
      "parameters\n",
      "tensor([  70.,  400.,  800., 1000., 1300., 2000.])\n",
      "optimizer.step() eseguito\n",
      "Epoch n°:\n",
      "1\n",
      "iteration number: 0 of 3\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.1291533809586576\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.349433417026974\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.5308493734579502\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.048746943543118\n",
      "parameters\n",
      "tensor([[[ 0.0133,  0.0351,  0.0393,  0.0390,  0.0377,  0.0309,  0.0325,\n",
      "           0.0374,  0.0368, -0.0381],\n",
      "         [-0.0133, -0.0351, -0.0393, -0.0390, -0.0377, -0.0309, -0.0325,\n",
      "          -0.0374, -0.0368,  0.0381]],\n",
      "\n",
      "        [[ 0.0240,  0.0331,  0.0359,  0.0400,  0.0373,  0.0285,  0.0322,\n",
      "           0.0366,  0.0371, -0.0384],\n",
      "         [-0.0240, -0.0331, -0.0359, -0.0400, -0.0373, -0.0285, -0.0322,\n",
      "          -0.0366, -0.0371,  0.0384]],\n",
      "\n",
      "        [[-0.0359, -0.0370, -0.0128, -0.0138, -0.0351, -0.0366, -0.0383,\n",
      "          -0.0385, -0.0371, -0.0398],\n",
      "         [ 0.0359,  0.0370,  0.0128,  0.0138,  0.0351,  0.0366,  0.0383,\n",
      "           0.0385,  0.0371,  0.0398]],\n",
      "\n",
      "        [[-0.0362, -0.0373, -0.0121, -0.0144, -0.0354, -0.0375, -0.0384,\n",
      "          -0.0380, -0.0367, -0.0398],\n",
      "         [ 0.0362,  0.0373,  0.0121,  0.0144,  0.0354,  0.0375,  0.0384,\n",
      "           0.0380,  0.0367,  0.0398]],\n",
      "\n",
      "        [[ 0.0058, -0.0076,  0.0057,  0.0251,  0.0147,  0.0053,  0.0177,\n",
      "           0.0273,  0.0247, -0.0384],\n",
      "         [-0.0058,  0.0076, -0.0057, -0.0251, -0.0147, -0.0053, -0.0177,\n",
      "          -0.0273, -0.0247,  0.0384]],\n",
      "\n",
      "        [[-0.0018, -0.0119, -0.0036,  0.0133,  0.0265,  0.0107,  0.0140,\n",
      "           0.0268,  0.0257, -0.0388],\n",
      "         [ 0.0018,  0.0119,  0.0036, -0.0133, -0.0265, -0.0107, -0.0140,\n",
      "          -0.0268, -0.0257,  0.0388]],\n",
      "\n",
      "        [[-0.0323, -0.0357, -0.0390, -0.0314, -0.0310, -0.0336, -0.0345,\n",
      "          -0.0348, -0.0338, -0.0346],\n",
      "         [ 0.0323,  0.0357,  0.0390,  0.0314,  0.0310,  0.0336,  0.0345,\n",
      "           0.0348,  0.0338,  0.0346]],\n",
      "\n",
      "        [[-0.0378, -0.0387, -0.0389, -0.0319,  0.0112, -0.0108, -0.0350,\n",
      "          -0.0342, -0.0361, -0.0358],\n",
      "         [ 0.0378,  0.0387,  0.0389,  0.0319, -0.0112,  0.0108,  0.0350,\n",
      "           0.0342,  0.0361,  0.0358]],\n",
      "\n",
      "        [[-0.0335, -0.0363, -0.0338, -0.0060, -0.0143, -0.0391, -0.0389,\n",
      "          -0.0381, -0.0370, -0.0394],\n",
      "         [ 0.0335,  0.0363,  0.0338,  0.0060,  0.0143,  0.0391,  0.0389,\n",
      "           0.0381,  0.0370,  0.0394]]])\n",
      "parameters\n",
      "tensor([ 0.0633,  0.0274, -0.0252,  ..., -0.0179, -0.0197, -0.0102])\n",
      "parameters\n",
      "tensor([[1.0099, 0.9967, 0.9973,  ..., 1.0222, 1.0207, 0.9607],\n",
      "        [1.0087, 1.0005, 1.0020,  ..., 1.0197, 1.0191, 0.9606],\n",
      "        [0.9878, 0.9686, 0.9909,  ..., 1.0117, 1.0107, 0.9606],\n",
      "        ...,\n",
      "        [0.9991, 1.0287, 1.0366,  ..., 1.0194, 1.0186, 0.9624],\n",
      "        [1.0013, 1.0318, 1.0377,  ..., 1.0156, 1.0154, 0.9629],\n",
      "        [1.0029, 1.0328, 1.0379,  ..., 1.0211, 1.0199, 0.9628]])\n",
      "parameters\n",
      "tensor([4.9862])\n",
      "parameters\n",
      "tensor([ 0.0000e+00, -3.8103e-05, -3.4582e-04,  ...,  1.6973e-05,\n",
      "         5.5884e-05,  2.0441e-05])\n",
      "parameters\n",
      "tensor([-4.9906, -4.6620, -4.3544, -4.0512, -3.7498, -3.4484, -3.1459, -2.8659,\n",
      "        -2.5643, -2.2724, -2.0046, -1.7058, -1.3953, -1.0710, -0.7636, -0.4691,\n",
      "        -0.1756,  0.1272,  0.4296,  0.7325,  1.0358,  1.3394,  1.6427,  1.9447,\n",
      "         2.2477,  2.5511,  2.8538,  3.1570,  3.4598,  3.7630,  4.0663,  4.3690,\n",
      "         4.6722,  4.9749])\n",
      "parameters\n",
      "tensor([  70.,  400.,  800., 1000., 1300., 2000.])\n",
      "optimizer.step() eseguito\n",
      "iteration number: 1 of 3\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.0920456349750776\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.356815840610013\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.2937478193504957\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.0694996323020396\n",
      "parameters\n",
      "tensor([[[ 0.0120,  0.0423,  0.0489,  0.0484,  0.0468,  0.0365,  0.0387,\n",
      "           0.0457,  0.0454, -0.0477],\n",
      "         [-0.0120, -0.0423, -0.0489, -0.0484, -0.0468, -0.0365, -0.0387,\n",
      "          -0.0457, -0.0454,  0.0477]],\n",
      "\n",
      "        [[ 0.0258,  0.0382,  0.0437,  0.0495,  0.0462,  0.0314,  0.0381,\n",
      "           0.0449,  0.0456, -0.0481],\n",
      "         [-0.0258, -0.0382, -0.0437, -0.0495, -0.0462, -0.0314, -0.0381,\n",
      "          -0.0449, -0.0456,  0.0481]],\n",
      "\n",
      "        [[-0.0441, -0.0457, -0.0216, -0.0229, -0.0444, -0.0462, -0.0480,\n",
      "          -0.0483, -0.0467, -0.0497],\n",
      "         [ 0.0441,  0.0457,  0.0216,  0.0229,  0.0444,  0.0462,  0.0480,\n",
      "           0.0483,  0.0467,  0.0497]],\n",
      "\n",
      "        [[-0.0443, -0.0466, -0.0209, -0.0237, -0.0447, -0.0471, -0.0482,\n",
      "          -0.0478, -0.0463, -0.0498],\n",
      "         [ 0.0443,  0.0466,  0.0209,  0.0237,  0.0447,  0.0471,  0.0482,\n",
      "           0.0478,  0.0463,  0.0498]],\n",
      "\n",
      "        [[ 0.0020, -0.0159, -0.0013,  0.0290,  0.0104, -0.0003,  0.0162,\n",
      "           0.0304,  0.0268, -0.0480],\n",
      "         [-0.0020,  0.0159,  0.0013, -0.0290, -0.0104,  0.0003, -0.0162,\n",
      "          -0.0304, -0.0268,  0.0480]],\n",
      "\n",
      "        [[-0.0088, -0.0210, -0.0111,  0.0112,  0.0253,  0.0056,  0.0117,\n",
      "           0.0303,  0.0280, -0.0485],\n",
      "         [ 0.0088,  0.0210,  0.0111, -0.0112, -0.0253, -0.0056, -0.0117,\n",
      "          -0.0303, -0.0280,  0.0485]],\n",
      "\n",
      "        [[-0.0391, -0.0439, -0.0486, -0.0395, -0.0375, -0.0413, -0.0427,\n",
      "          -0.0436, -0.0421, -0.0425],\n",
      "         [ 0.0391,  0.0439,  0.0486,  0.0395,  0.0375,  0.0413,  0.0427,\n",
      "           0.0436,  0.0421,  0.0425]],\n",
      "\n",
      "        [[-0.0454, -0.0482, -0.0482, -0.0387,  0.0047, -0.0186, -0.0434,\n",
      "          -0.0425, -0.0444, -0.0441],\n",
      "         [ 0.0454,  0.0482,  0.0482,  0.0387, -0.0047,  0.0186,  0.0434,\n",
      "           0.0425,  0.0444,  0.0441]],\n",
      "\n",
      "        [[-0.0398, -0.0442, -0.0422, -0.0133, -0.0234, -0.0490, -0.0488,\n",
      "          -0.0477, -0.0467, -0.0493],\n",
      "         [ 0.0398,  0.0442,  0.0422,  0.0133,  0.0234,  0.0490,  0.0488,\n",
      "           0.0477,  0.0467,  0.0493]]])\n",
      "parameters\n",
      "tensor([ 0.0544,  0.0313, -0.0269,  ..., -0.0145, -0.0189, -0.0086])\n",
      "parameters\n",
      "tensor([[1.0056, 0.9949, 0.9912,  ..., 1.0229, 1.0195, 0.9508],\n",
      "        [1.0044, 0.9998, 0.9975,  ..., 1.0194, 1.0180, 0.9507],\n",
      "        [0.9801, 0.9628, 0.9829,  ..., 1.0078, 1.0055, 0.9508],\n",
      "        ...,\n",
      "        [0.9927, 1.0290, 1.0432,  ..., 1.0182, 1.0182, 0.9530],\n",
      "        [0.9953, 1.0338, 1.0451,  ..., 1.0134, 1.0145, 0.9536],\n",
      "        [0.9970, 1.0354, 1.0454,  ..., 1.0210, 1.0206, 0.9535]])\n",
      "parameters\n",
      "tensor([4.9771])\n",
      "parameters\n",
      "tensor([ 0.0000e+00, -8.8563e-05, -4.1600e-04,  ...,  7.4590e-06,\n",
      "         2.1533e-05,  7.9076e-05])\n",
      "parameters\n",
      "tensor([-4.9824, -4.6528, -4.3444, -4.0412, -3.7401, -3.4389, -3.1364, -2.8568,\n",
      "        -2.5555, -2.2658, -2.0140, -1.7154, -1.3916, -1.0636, -0.7556, -0.4662,\n",
      "        -0.1847,  0.1181,  0.4205,  0.7234,  1.0267,  1.3303,  1.6337,  1.9354,\n",
      "         2.2385,  2.5419,  2.8446,  3.1479,  3.4505,  3.7537,  4.0570,  4.3597,\n",
      "         4.6629,  4.9656])\n",
      "parameters\n",
      "tensor([  70.,  400.,  800., 1000., 1300., 2000.])\n",
      "optimizer.step() eseguito\n",
      "iteration number: 2 of 3\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "2.7421427463416075\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "2.7623410836593774\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "2.61688820099402\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "2.548137506313921\n",
      "parameters\n",
      "tensor([[[ 0.0088,  0.0496,  0.0586,  0.0576,  0.0555,  0.0417,  0.0454,\n",
      "           0.0539,  0.0537, -0.0573],\n",
      "         [-0.0088, -0.0496, -0.0586, -0.0576, -0.0555, -0.0417, -0.0454,\n",
      "          -0.0539, -0.0537,  0.0573]],\n",
      "\n",
      "        [[ 0.0279,  0.0443,  0.0508,  0.0589,  0.0551,  0.0343,  0.0450,\n",
      "           0.0532,  0.0539, -0.0578],\n",
      "         [-0.0279, -0.0443, -0.0508, -0.0589, -0.0551, -0.0343, -0.0450,\n",
      "          -0.0532, -0.0539,  0.0578]],\n",
      "\n",
      "        [[-0.0527, -0.0546, -0.0305, -0.0317, -0.0538, -0.0559, -0.0576,\n",
      "          -0.0581, -0.0564, -0.0596],\n",
      "         [ 0.0527,  0.0546,  0.0305,  0.0317,  0.0538,  0.0559,  0.0576,\n",
      "           0.0581,  0.0564,  0.0596]],\n",
      "\n",
      "        [[-0.0528, -0.0561, -0.0291, -0.0332, -0.0543, -0.0568, -0.0580,\n",
      "          -0.0575, -0.0561, -0.0599],\n",
      "         [ 0.0528,  0.0561,  0.0291,  0.0332,  0.0543,  0.0568,  0.0580,\n",
      "           0.0575,  0.0561,  0.0599]],\n",
      "\n",
      "        [[-0.0036, -0.0244, -0.0090,  0.0303,  0.0050, -0.0067,  0.0145,\n",
      "           0.0330,  0.0283, -0.0576],\n",
      "         [ 0.0036,  0.0244,  0.0090, -0.0303, -0.0050,  0.0067, -0.0145,\n",
      "          -0.0330, -0.0283,  0.0576]],\n",
      "\n",
      "        [[-0.0158, -0.0298, -0.0189,  0.0083,  0.0232, -0.0007,  0.0086,\n",
      "           0.0330,  0.0295, -0.0582],\n",
      "         [ 0.0158,  0.0298,  0.0189, -0.0083, -0.0232,  0.0007, -0.0086,\n",
      "          -0.0330, -0.0295,  0.0582]],\n",
      "\n",
      "        [[-0.0462, -0.0525, -0.0583, -0.0480, -0.0447, -0.0495, -0.0509,\n",
      "          -0.0525, -0.0506, -0.0508],\n",
      "         [ 0.0462,  0.0525,  0.0583,  0.0480,  0.0447,  0.0495,  0.0509,\n",
      "           0.0525,  0.0506,  0.0508]],\n",
      "\n",
      "        [[-0.0537, -0.0579, -0.0571, -0.0460, -0.0004, -0.0259, -0.0517,\n",
      "          -0.0509, -0.0528, -0.0524],\n",
      "         [ 0.0537,  0.0579,  0.0571,  0.0460,  0.0004,  0.0259,  0.0517,\n",
      "           0.0509,  0.0528,  0.0524]],\n",
      "\n",
      "        [[-0.0471, -0.0527, -0.0512, -0.0214, -0.0327, -0.0590, -0.0586,\n",
      "          -0.0574, -0.0563, -0.0591],\n",
      "         [ 0.0471,  0.0527,  0.0512,  0.0214,  0.0327,  0.0590,  0.0586,\n",
      "           0.0574,  0.0563,  0.0591]]])\n",
      "parameters\n",
      "tensor([ 0.0466,  0.0347, -0.0278,  ..., -0.0122, -0.0169, -0.0038])\n",
      "parameters\n",
      "tensor([[1.0017, 0.9904, 0.9842,  ..., 1.0214, 1.0160, 0.9409],\n",
      "        [1.0013, 0.9962, 0.9915,  ..., 1.0167, 1.0142, 0.9408],\n",
      "        [0.9730, 0.9557, 0.9743,  ..., 1.0025, 0.9990, 0.9409],\n",
      "        ...,\n",
      "        [0.9854, 1.0280, 1.0498,  ..., 1.0171, 1.0167, 0.9434],\n",
      "        [0.9883, 1.0346, 1.0518,  ..., 1.0118, 1.0126, 0.9442],\n",
      "        [0.9901, 1.0367, 1.0524,  ..., 1.0214, 1.0204, 0.9440]])\n",
      "parameters\n",
      "tensor([4.9679])\n",
      "parameters\n",
      "tensor([ 0.0000e+00, -1.5439e-04, -4.8976e-04,  ...,  2.7030e-05,\n",
      "        -1.4106e-05,  8.2618e-05])\n",
      "parameters\n",
      "tensor([-4.9755, -4.6450, -4.3346, -4.0312, -3.7302, -3.4292, -3.1268, -2.8475,\n",
      "        -2.5464, -2.2600, -2.0235, -1.7218, -1.3855, -1.0553, -0.7471, -0.4658,\n",
      "        -0.1941,  0.1088,  0.4112,  0.7142,  1.0174,  1.3212,  1.6246,  1.9260,\n",
      "         2.2291,  2.5327,  2.8353,  3.1387,  3.4412,  3.7444,  4.0478,  4.3504,\n",
      "         4.6536,  4.9563])\n",
      "parameters\n",
      "tensor([  70.,  400.,  800., 1000., 1300., 2000.])\n",
      "optimizer.step() eseguito\n",
      "Epoch n°:\n",
      "2\n",
      "iteration number: 0 of 3\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "Generating Pink Noise\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "4.319259006537829\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "Generating Pink Noise\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "4.022283538166662\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "Generating Pink Noise\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "5.293878369757016\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "Generating Pink Noise\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "4.211224088803978\n",
      "parameters\n",
      "tensor([[[ 0.0033,  0.0455,  0.0566,  0.0583,  0.0539,  0.0387,  0.0476,\n",
      "           0.0583,  0.0586, -0.0671],\n",
      "         [-0.0033, -0.0455, -0.0566, -0.0583, -0.0539, -0.0387, -0.0476,\n",
      "          -0.0583, -0.0586,  0.0671]],\n",
      "\n",
      "        [[ 0.0282,  0.0400,  0.0469,  0.0573,  0.0525,  0.0300,  0.0475,\n",
      "           0.0576,  0.0572, -0.0677],\n",
      "         [-0.0282, -0.0400, -0.0469, -0.0573, -0.0525, -0.0300, -0.0475,\n",
      "          -0.0576, -0.0572,  0.0677]],\n",
      "\n",
      "        [[-0.0594, -0.0615, -0.0368, -0.0384, -0.0615, -0.0640, -0.0664,\n",
      "          -0.0671, -0.0661, -0.0695],\n",
      "         [ 0.0594,  0.0615,  0.0368,  0.0384,  0.0615,  0.0640,  0.0664,\n",
      "           0.0671,  0.0661,  0.0695]],\n",
      "\n",
      "        [[-0.0591, -0.0626, -0.0357, -0.0396, -0.0613, -0.0645, -0.0672,\n",
      "          -0.0667, -0.0653, -0.0695],\n",
      "         [ 0.0591,  0.0626,  0.0357,  0.0396,  0.0613,  0.0645,  0.0672,\n",
      "           0.0667,  0.0653,  0.0695]],\n",
      "\n",
      "        [[-0.0106, -0.0317, -0.0149,  0.0254, -0.0012, -0.0139,  0.0097,\n",
      "           0.0309,  0.0262, -0.0674],\n",
      "         [ 0.0106,  0.0317,  0.0149, -0.0254,  0.0012,  0.0139, -0.0097,\n",
      "          -0.0309, -0.0262,  0.0674]],\n",
      "\n",
      "        [[-0.0218, -0.0366, -0.0254,  0.0030,  0.0178, -0.0075,  0.0031,\n",
      "           0.0311,  0.0269, -0.0680],\n",
      "         [ 0.0218,  0.0366,  0.0254, -0.0030, -0.0178,  0.0075, -0.0031,\n",
      "          -0.0311, -0.0269,  0.0680]],\n",
      "\n",
      "        [[-0.0542, -0.0605, -0.0643, -0.0543, -0.0526, -0.0536, -0.0597,\n",
      "          -0.0618, -0.0593, -0.0595],\n",
      "         [ 0.0542,  0.0605,  0.0643,  0.0543,  0.0526,  0.0536,  0.0597,\n",
      "           0.0618,  0.0593,  0.0595]],\n",
      "\n",
      "        [[-0.0604, -0.0645, -0.0626, -0.0523, -0.0071, -0.0335, -0.0570,\n",
      "          -0.0595, -0.0616, -0.0611],\n",
      "         [ 0.0604,  0.0645,  0.0626,  0.0523,  0.0071,  0.0335,  0.0570,\n",
      "           0.0595,  0.0616,  0.0611]],\n",
      "\n",
      "        [[-0.0531, -0.0587, -0.0570, -0.0274, -0.0397, -0.0662, -0.0676,\n",
      "          -0.0660, -0.0651, -0.0681],\n",
      "         [ 0.0531,  0.0587,  0.0570,  0.0274,  0.0397,  0.0662,  0.0676,\n",
      "           0.0660,  0.0651,  0.0681]]])\n",
      "parameters\n",
      "tensor([ 0.0385,  0.0359, -0.0257,  ..., -0.0087, -0.0117, -0.0017])\n",
      "parameters\n",
      "tensor([[0.9963, 0.9850, 0.9784,  ..., 1.0161, 1.0102, 0.9311],\n",
      "        [0.9958, 0.9908, 0.9858,  ..., 1.0111, 1.0084, 0.9308],\n",
      "        [0.9672, 0.9500, 0.9682,  ..., 0.9964, 0.9924, 0.9311],\n",
      "        ...,\n",
      "        [0.9789, 1.0229, 1.0469,  ..., 1.0121, 1.0118, 0.9336],\n",
      "        [0.9818, 1.0296, 1.0482,  ..., 1.0067, 1.0075, 0.9345],\n",
      "        [0.9834, 1.0318, 1.0493,  ..., 1.0174, 1.0165, 0.9343]])\n",
      "parameters\n",
      "tensor([4.9588])\n",
      "parameters\n",
      "tensor([ 0.0000e+00, -2.3035e-04, -5.6798e-04,  ...,  4.8393e-05,\n",
      "        -2.4462e-05,  5.4759e-05])\n",
      "parameters\n",
      "tensor([-4.9679, -4.6366, -4.3256, -4.0224, -3.7208, -3.4195, -3.1169, -2.8380,\n",
      "        -2.5372, -2.2547, -2.0326, -1.7235, -1.3782, -1.0465, -0.7387, -0.4687,\n",
      "        -0.2037,  0.0994,  0.4020,  0.7050,  1.0081,  1.3122,  1.6157,  1.9167,\n",
      "         2.2198,  2.5236,  2.8261,  3.1295,  3.4318,  3.7351,  4.0386,  4.3411,\n",
      "         4.6444,  4.9469])\n",
      "parameters\n",
      "tensor([  70.,  400.,  800., 1000., 1300., 2000.])\n",
      "optimizer.step() eseguito\n",
      "iteration number: 1 of 3\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "Generating Pink Noise\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "4.435923703024727\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "Generating Pink Noise\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "4.888661101788305\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "Generating Pink Noise\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "4.365805988839246\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "Generating Pink Noise\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.966248846614893\n",
      "parameters\n",
      "tensor([[[-0.0037,  0.0402,  0.0538,  0.0551,  0.0501,  0.0343,  0.0483,\n",
      "           0.0626,  0.0628, -0.0770],\n",
      "         [ 0.0037, -0.0402, -0.0538, -0.0551, -0.0501, -0.0343, -0.0483,\n",
      "          -0.0626, -0.0628,  0.0770]],\n",
      "\n",
      "        [[ 0.0233,  0.0338,  0.0411,  0.0529,  0.0478,  0.0240,  0.0470,\n",
      "           0.0612,  0.0593, -0.0776],\n",
      "         [-0.0233, -0.0338, -0.0411, -0.0529, -0.0478, -0.0240, -0.0470,\n",
      "          -0.0612, -0.0593,  0.0776]],\n",
      "\n",
      "        [[-0.0666, -0.0689, -0.0439, -0.0461, -0.0697, -0.0726, -0.0756,\n",
      "          -0.0764, -0.0759, -0.0795],\n",
      "         [ 0.0666,  0.0689,  0.0439,  0.0461,  0.0697,  0.0726,  0.0756,\n",
      "           0.0764,  0.0759,  0.0795]],\n",
      "\n",
      "        [[-0.0664, -0.0701, -0.0432, -0.0460, -0.0692, -0.0728, -0.0768,\n",
      "          -0.0763, -0.0748, -0.0793],\n",
      "         [ 0.0664,  0.0701,  0.0432,  0.0460,  0.0692,  0.0728,  0.0768,\n",
      "           0.0763,  0.0748,  0.0793]],\n",
      "\n",
      "        [[-0.0181, -0.0398, -0.0214,  0.0191, -0.0085, -0.0219,  0.0040,\n",
      "           0.0273,  0.0221, -0.0772],\n",
      "         [ 0.0181,  0.0398,  0.0214, -0.0191,  0.0085,  0.0219, -0.0040,\n",
      "          -0.0273, -0.0221,  0.0772]],\n",
      "\n",
      "        [[-0.0290, -0.0443, -0.0330, -0.0038,  0.0111, -0.0153, -0.0038,\n",
      "           0.0272,  0.0224, -0.0779],\n",
      "         [ 0.0290,  0.0443,  0.0330,  0.0038, -0.0111,  0.0153,  0.0038,\n",
      "          -0.0272, -0.0224,  0.0779]],\n",
      "\n",
      "        [[-0.0607, -0.0679, -0.0705, -0.0612, -0.0602, -0.0597, -0.0688,\n",
      "          -0.0711, -0.0685, -0.0686],\n",
      "         [ 0.0607,  0.0679,  0.0705,  0.0612,  0.0602,  0.0597,  0.0688,\n",
      "           0.0711,  0.0685,  0.0686]],\n",
      "\n",
      "        [[-0.0665, -0.0716, -0.0676, -0.0586, -0.0137, -0.0410, -0.0637,\n",
      "          -0.0681, -0.0693, -0.0696],\n",
      "         [ 0.0665,  0.0716,  0.0676,  0.0586,  0.0137,  0.0410,  0.0637,\n",
      "           0.0681,  0.0693,  0.0696]],\n",
      "\n",
      "        [[-0.0603, -0.0660, -0.0629, -0.0333, -0.0475, -0.0741, -0.0770,\n",
      "          -0.0751, -0.0743, -0.0774],\n",
      "         [ 0.0603,  0.0660,  0.0629,  0.0333,  0.0475,  0.0741,  0.0770,\n",
      "           0.0751,  0.0743,  0.0774]]])\n",
      "parameters\n",
      "tensor([ 0.0300,  0.0337, -0.0210,  ..., -0.0041, -0.0050, -0.0047])\n",
      "parameters\n",
      "tensor([[0.9898, 0.9782, 0.9715,  ..., 1.0108, 1.0039, 0.9211],\n",
      "        [0.9898, 0.9840, 0.9791,  ..., 1.0056, 1.0018, 0.9208],\n",
      "        [0.9608, 0.9430, 0.9610,  ..., 0.9900, 0.9853, 0.9211],\n",
      "        ...,\n",
      "        [0.9718, 1.0178, 1.0443,  ..., 1.0072, 1.0063, 0.9238],\n",
      "        [0.9748, 1.0249, 1.0444,  ..., 1.0018, 1.0018, 0.9248],\n",
      "        [0.9762, 1.0270, 1.0461,  ..., 1.0136, 1.0119, 0.9246]])\n",
      "parameters\n",
      "tensor([4.9494])\n",
      "parameters\n",
      "tensor([ 0.0000e+00, -2.8421e-04, -6.0275e-04,  ...,  3.7120e-05,\n",
      "        -5.4843e-06,  1.5545e-05])\n",
      "parameters\n",
      "tensor([-4.9600, -4.6279, -4.3165, -4.0132, -3.7112, -3.4096, -3.1070, -2.8284,\n",
      "        -2.5282, -2.2499, -2.0392, -1.7205, -1.3702, -1.0373, -0.7313, -0.4741,\n",
      "        -0.2135,  0.0899,  0.3929,  0.6958,  0.9989,  1.3033,  1.6069,  1.9074,\n",
      "         2.2105,  2.5144,  2.8168,  3.1203,  3.4224,  3.7258,  4.0294,  4.3317,\n",
      "         4.6351,  4.9375])\n",
      "parameters\n",
      "tensor([  70.,  400.,  800., 1000., 1300., 2000.])\n",
      "optimizer.step() eseguito\n",
      "iteration number: 2 of 3\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "Generating Pink Noise\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.6290332586939718\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "Generating Pink Noise\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "4.420757092313489\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "Generating Pink Noise\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.939180193448582\n",
      "Omnidirectional case\n",
      "loss function calcolata\n",
      "Generating Pink Noise\n",
      "loss.backward() eseguito\n",
      "loss:\n",
      "3.6088045366568675\n",
      "parameters\n",
      "tensor([[[-0.0107,  0.0347,  0.0511,  0.0512,  0.0460,  0.0298,  0.0504,\n",
      "           0.0675,  0.0677, -0.0868],\n",
      "         [ 0.0107, -0.0347, -0.0511, -0.0512, -0.0460, -0.0298, -0.0504,\n",
      "          -0.0675, -0.0677,  0.0868]],\n",
      "\n",
      "        [[ 0.0179,  0.0275,  0.0356,  0.0483,  0.0428,  0.0179,  0.0473,\n",
      "           0.0652,  0.0621, -0.0875],\n",
      "         [-0.0179, -0.0275, -0.0356, -0.0483, -0.0428, -0.0179, -0.0473,\n",
      "          -0.0652, -0.0621,  0.0875]],\n",
      "\n",
      "        [[-0.0737, -0.0763, -0.0511, -0.0542, -0.0783, -0.0813, -0.0847,\n",
      "          -0.0855, -0.0858, -0.0896],\n",
      "         [ 0.0737,  0.0763,  0.0511,  0.0542,  0.0783,  0.0813,  0.0847,\n",
      "           0.0855,  0.0858,  0.0896]],\n",
      "\n",
      "        [[-0.0738, -0.0779, -0.0506, -0.0520, -0.0775, -0.0813, -0.0858,\n",
      "          -0.0855, -0.0843, -0.0893],\n",
      "         [ 0.0738,  0.0779,  0.0506,  0.0520,  0.0775,  0.0813,  0.0858,\n",
      "           0.0855,  0.0843,  0.0893]],\n",
      "\n",
      "        [[-0.0264, -0.0483, -0.0278,  0.0121, -0.0167, -0.0304, -0.0009,\n",
      "           0.0237,  0.0175, -0.0872],\n",
      "         [ 0.0264,  0.0483,  0.0278, -0.0121,  0.0167,  0.0304,  0.0009,\n",
      "          -0.0237, -0.0175,  0.0872]],\n",
      "\n",
      "        [[-0.0359, -0.0516, -0.0399, -0.0108,  0.0038, -0.0229, -0.0092,\n",
      "           0.0238,  0.0183, -0.0879],\n",
      "         [ 0.0359,  0.0516,  0.0399,  0.0108, -0.0038,  0.0229,  0.0092,\n",
      "          -0.0238, -0.0183,  0.0879]],\n",
      "\n",
      "        [[-0.0681, -0.0761, -0.0763, -0.0690, -0.0679, -0.0670, -0.0782,\n",
      "          -0.0796, -0.0776, -0.0781],\n",
      "         [ 0.0681,  0.0761,  0.0763,  0.0690,  0.0679,  0.0670,  0.0782,\n",
      "           0.0796,  0.0776,  0.0781]],\n",
      "\n",
      "        [[-0.0719, -0.0781, -0.0724, -0.0646, -0.0201, -0.0474, -0.0697,\n",
      "          -0.0759, -0.0762, -0.0775],\n",
      "         [ 0.0719,  0.0781,  0.0724,  0.0646,  0.0201,  0.0474,  0.0697,\n",
      "           0.0759,  0.0762,  0.0775]],\n",
      "\n",
      "        [[-0.0674, -0.0735, -0.0687, -0.0390, -0.0558, -0.0823, -0.0855,\n",
      "          -0.0837, -0.0831, -0.0867],\n",
      "         [ 0.0674,  0.0735,  0.0687,  0.0390,  0.0558,  0.0823,  0.0855,\n",
      "           0.0837,  0.0831,  0.0867]]])\n",
      "parameters\n",
      "tensor([ 0.0224,  0.0304, -0.0156,  ...,  0.0003, -0.0003, -0.0041])\n",
      "parameters\n",
      "tensor([[0.9835, 0.9719, 0.9654,  ..., 1.0063, 0.9984, 0.9113],\n",
      "        [0.9833, 0.9776, 0.9730,  ..., 1.0008, 0.9960, 0.9108],\n",
      "        [0.9545, 0.9365, 0.9547,  ..., 0.9843, 0.9787, 0.9113],\n",
      "        ...,\n",
      "        [0.9644, 1.0123, 1.0413,  ..., 1.0033, 1.0015, 0.9138],\n",
      "        [0.9677, 1.0200, 1.0404,  ..., 0.9978, 0.9961, 0.9149],\n",
      "        [0.9688, 1.0219, 1.0426,  ..., 1.0110, 1.0076, 0.9147]])\n",
      "parameters\n",
      "tensor([4.9400])\n",
      "parameters\n",
      "tensor([ 0.0000e+00, -3.3276e-04, -6.4047e-04,  ...,  5.5645e-06,\n",
      "         2.2933e-05, -2.3267e-05])\n",
      "parameters\n",
      "tensor([-4.9527, -4.6192, -4.3072, -4.0038, -3.7015, -3.3997, -3.0973, -2.8192,\n",
      "        -2.5200, -2.2468, -2.0409, -1.7150, -1.3617, -1.0278, -0.7244, -0.4806,\n",
      "        -0.2234,  0.0805,  0.3839,  0.6869,  0.9898,  1.2943,  1.5980,  1.8981,\n",
      "         2.2012,  2.5052,  2.8076,  3.1111,  3.4131,  3.7165,  4.0201,  4.3224,\n",
      "         4.6259,  4.9282])\n",
      "parameters\n",
      "tensor([  70.,  400.,  800., 1000., 1300., 2000.])\n",
      "optimizer.step() eseguito\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "if not skip_train:\n",
    "    print(\"Training\")\n",
    "\n",
    "    #Initialize Listeners\n",
    "    Ls = initialize(indices=D.train_indices,\n",
    "                    listener_xyzs=D.xyzs,\n",
    "                    source_xyz=D.speaker_xyz,\n",
    "                    surfaces=D.all_surfaces,\n",
    "                    load_dir=load_dir,\n",
    "                    #######################################\n",
    "                    rendering_methods = D.rendering_methods, #############should define the rendering method for every listener!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                    mic_orientations = D.mic_orientations,#############and all this other stuff!!!!!!!!!!!\n",
    "                    mic_0_gains= D.mic_0_gains, ############################it's needed for the microphone responses!!!!!!!!!!!!!!!!!!!!!!\n",
    "                    mic_180_loss = D.mic_180_loss,\n",
    "                    cardioid_exponents = D.cardioid_exponents)\n",
    "    if continue_train:\n",
    "        R.load_state_dict(torch.load(os.path.join(save_dir,\"weights.pt\"))['model_state_dict'])\n",
    "\n",
    "    losses = train.train_loop(R=R, Ls=Ls, train_gt_audio=gt_audio[D.train_indices], D=D,\n",
    "                        n_epochs = n_epochs, batch_size = batch_size, lr = lr, loss_fcn = loss_fcn,\n",
    "                        save_dir=save_dir,\n",
    "                        pink_noise_supervision = pink_noise_supervision,\n",
    "                        pink_start_epoch=pink_start_epoch,\n",
    "                        continue_train = continue_train, fs=fs)\n",
    "\n",
    "else:\n",
    "    R.load_state_dict(torch.load(os.path.join(save_dir,\"weights.pt\"))['model_state_dict'])\n",
    "    R.train = False\n",
    "    R.toa_perturb = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_file = torch.load(save_dir + '/weights.pt', map_location=device)\n",
    "R.energy_vector = nn.Parameter(pt_file['model_state_dict']['energy_vector'])\n",
    "R.source_response = nn.Parameter(pt_file['model_state_dict']['source_response'])\n",
    "R.directivity_sphere = nn.Parameter(pt_file['model_state_dict']['directivity_sphere'])\n",
    "R.decay = nn.Parameter(pt_file['model_state_dict']['decay'])\n",
    "R.RIR_residual = nn.Parameter(pt_file['model_state_dict']['RIR_residual'])\n",
    "R.spline_values = nn.Parameter(pt_file['model_state_dict']['spline_values'])\n",
    "\n",
    "R.bp_ord_cut_freqs = nn.Parameter(pt_file['model_state_dict']['bp_ord_cut_freqs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note - this function relies on precomputed reflection paths\n",
    "#########above in the original code, I added the case where there are no precomputed paths\n",
    "def inference(R, source_xyz, xyzs, load_dir, source_axis_1=None, source_axis_2=None):\n",
    "    \"\"\"\n",
    "    Render monoaural RIRs at given precomputed reflection paths.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    R: Renderer\n",
    "        renderer to perform inference on\n",
    "    source_xyz: np.array (3,)\n",
    "        3D location of source in meters\n",
    "    xyzs: np.array (N, 3)\n",
    "        set of listener locations to render at\n",
    "    load_dir: str\n",
    "        directory to load precomputed listener paths\n",
    "    source_axis_1: np.array (3,)\n",
    "        first axis specifying virtual source rotation,\n",
    "        default is None which is (1,0,0)\n",
    "    source_axis_2: np.array (3,)\n",
    "        second axis specifying virtual source rotation,\n",
    "        default is None which is (0,1,0)    \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predictions: np.array (N, T) of predicted RIRs    \n",
    "    \"\"\"\n",
    "\n",
    "    predictions = np.zeros((xyzs.shape[0], R.RIR_length))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        R.toa_perturb = False\n",
    "        for idx in range(xyzs.shape[0]):\n",
    "            print(idx, flush=True)\n",
    "            \n",
    "            if load_dir is None: \n",
    "                # Tracing from Scratch\n",
    "                reflections, transmissions, delays, start_directions, end_directions = (\n",
    "                    trace1.get_reflections_transmissions_and_delays(\n",
    "                    source=source_xyz, dest=xyzs[idx], surfaces=D.all_surfaces, speed_of_sound=D.speed_of_sound,\n",
    "                    max_order=D.max_order,parallel_surface_pairs=D.parallel_surface_pairs, max_axial_order=D.max_axial_order)\n",
    "                )\n",
    "                \n",
    "            else:   \n",
    "                reflections = np.load(os.path.join(load_dir, \"reflections/\"+str(idx)+\".npy\"), allow_pickle=True)\n",
    "                transmissions = np.load(os.path.join(load_dir, \"transmissions/\"+str(idx)+\".npy\"), allow_pickle=True)\n",
    "                delays = np.load(os.path.join(load_dir, \"delays/\"+str(idx)+\".npy\"),allow_pickle=True)\n",
    "                start_directions = np.load(os.path.join(load_dir, \"starts/\"+str(idx)+\".npy\"))\n",
    "\n",
    "            L = render.ListenerLocation(\n",
    "                source_xyz=source_xyz,\n",
    "                listener_xyz=xyzs[idx],\n",
    "                n_surfaces=R.n_surfaces,\n",
    "                reflections=reflections,\n",
    "                transmissions=transmissions,\n",
    "                delays=delays,\n",
    "                start_directions = start_directions)\n",
    "\n",
    "            predict = R.render_RIR(L, source_axis_1=source_axis_1, source_axis_2=source_axis_2)\n",
    "            predictions[idx] = predict.detach().cpu().numpy()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Inference, rendering RIR\n",
    "\"\"\"\n",
    "R.train = False\n",
    "R.toa_perturb = False\n",
    "pred_dir = os.path.join(save_dir, \"predictions\")\n",
    "if not skip_inference:\n",
    "    pred_rirs = inference(R=R, source_xyz=D.speaker_xyz, xyzs=D.xyzs, load_dir=load_dir)\n",
    "    train.makedir_if_needed(pred_dir)\n",
    "    np.save(os.path.join(pred_dir, \"pred_rirs.npy\"), pred_rirs)\n",
    "\n",
    "    if not skip_music:\n",
    "        pred_music = evaluate.render_music(pred_rirs, D.music_dls)    \n",
    "        np.save(os.path.join(pred_dir,\"pred_musics.npy\"), pred_music)\n",
    "else:\n",
    "    pred_rirs = np.load(os.path.join(pred_dir, \"pred_rirs.npy\"))\n",
    "    pred_music = np.load(os.path.join(pred_dir, \"pred_musics.npy\"))\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Evaluation of Monoaural Audio Using Metrics\n",
    "\"\"\"\n",
    "if not skip_eval:\n",
    "    errors_dir = os.path.join(save_dir, \"errors\")\n",
    "    train.makedir_if_needed(errors_dir)\n",
    "    list_of_metrics = metrics.baseline_metrics\n",
    "\n",
    "    if valid:\n",
    "        eval_indices = D.valid_indices\n",
    "    else:\n",
    "        eval_indices = D.test_indices\n",
    "\n",
    "    # Evaluating RIR Interp\n",
    "    for eval_metric in list_of_metrics:\n",
    "\n",
    "        metric_name = eval_metric.__name__\n",
    "        errors = evaluate.compute_error(pred_rirs, gt_audio, metric=eval_metric) #original code\n",
    "        #errors = evaluate.compute_error(pred_rirs[eval_indices], gt_audio[eval_indices], metric=eval_metric)\n",
    "        \n",
    "        np.save(os.path.join(errors_dir, \"errors_\" + metric_name +\".npy\"), errors)\n",
    "        print(metric_name + \" Metric:\", flush=True)\n",
    "        print(np.mean(errors[eval_indices]))\n",
    "        #print(np.mean(errors))\n",
    "        \n",
    "    # Evaluating Music Interp\n",
    "    if not skip_music:\n",
    "        for eval_metric in list_of_metrics:\n",
    "\n",
    "            metric_name = eval_metric.__name__\n",
    "\n",
    "            # Computing Error\n",
    "            errors_music = evaluate.eval_music(pred_music, D.music, eval_metric)\n",
    "            #errors_music = evaluate.eval_music(pred_music[eval_indices], D.music[eval_indices], eval_metric)\n",
    "            \n",
    "            np.save(os.path.join(errors_dir, \"errors_music_\" + metric_name +\".npy\"), errors_music)\n",
    "            print(metric_name + \" Music Metric:\", flush=True)\n",
    "            print(np.mean(errors_music[eval_indices]))\n",
    "            #print(np.mean(errors_music))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binaural Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binauralize\n",
    "\n",
    "\"\"\"\n",
    "Binaural Rendering\n",
    "\"\"\"\n",
    "if not skip_binaural:\n",
    "    pred_binaural_RIRs = []\n",
    "    for i in range(D.bin_xyzs.shape[0]):\n",
    "        binaural_RIR_xyz = D.bin_xyzs[i]\n",
    "        bin_rir = binauralize.render_binaural(R=R, source_xyz = D.speaker_xyz,\n",
    "                                            source_axis_1=None, source_axis_2=None,\n",
    "                                            listener_xyz=binaural_RIR_xyz,\n",
    "                                            listener_forward=D.default_binaural_listener_forward, \n",
    "                                            listener_left=D.default_binaural_listener_left,\n",
    "                                            surfaces=D.all_surfaces,\n",
    "                                            speed_of_sound=D.speed_of_sound,\n",
    "                                            parallel_surface_pairs=D.parallel_surface_pairs,\n",
    "                                            max_order=D.max_order, max_axial_order=D.max_axial_order)\n",
    "\n",
    "        pred_binaural_RIRs.append(bin_rir)\n",
    "\n",
    "    pred_binaural_RIRs = np.array(pred_binaural_RIRs)\n",
    "    np.save(os.path.join(pred_dir, \"pred_bin_RIRs.npy\"), pred_binaural_RIRs)\n",
    "\n",
    "    if not skip_music:\n",
    "        pred_L = pred_binaural_RIRs[:,0,:]\n",
    "        pred_R = pred_binaural_RIRs[:,1,:]\n",
    "\n",
    "        pred_L_music = evaluate.render_music(pred_L, D.music_dls[:pred_L.shape[0]])\n",
    "        pred_R_music = evaluate.render_music(pred_R, D.music_dls[:pred_R.shape[0]])\n",
    "\n",
    "        pred_bin_music = np.stack((pred_L_music, pred_R_music), axis=2)\n",
    "        print(pred_bin_music.shape)\n",
    "        np.save(os.path.join(pred_dir, \"pred_bin_musics.npy\"), pred_bin_music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prova di ascolto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listener Loading From: precomputed/prova\n",
      "Listener Loading From: precomputed/prova\n"
     ]
    }
   ],
   "source": [
    "listener_1 = render.get_listener(source_xyz= np.array([5,3,1.5]), listener_xyz = np.array([5,7,1.5]), surfaces = D.all_surfaces, \n",
    "                               load_dir = load_dir, load_num = 0, speed_of_sound = D.speed_of_sound, \n",
    "                               max_order = D.max_order, parallel_surface_pairs = D.parallel_surface_pairs, \n",
    "                               max_axial_order = D.max_axial_order)\n",
    "\n",
    "listener_2 = render.get_listener(source_xyz= np.array([9.9,9.9,2.9]), listener_xyz = np.array([5,3,1.5]), surfaces = D.all_surfaces, \n",
    "                               load_dir = load_dir, load_num = 1, speed_of_sound = D.speed_of_sound, \n",
    "                               max_order = D.max_order, parallel_surface_pairs = D.parallel_surface_pairs, \n",
    "                               max_axial_order = D.max_axial_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RIR_1 = R.render_RIR(listener_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "RIR_2 = R.render_RIR(listener_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RIR_1 plot\n",
    "plt.plot(RIR_1.detach().cpu())\n",
    "plt.title(\"RIR_1\")\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RIR_2\" plot\n",
    "plt.plot(RIR_2.detach().cpu())\n",
    "plt.title(\"Plot\")\n",
    "plt.xlabel(\"Indice\")\n",
    "plt.ylabel(\"Valore\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59168/810690356.py:1: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  predicted_music_1 = evaluate.render_music(np.array([RIR_1.detach().cpu()]), np.array([D.music_dls[0]]), device = device)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predicted_music_1 \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mrender_music(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRIR_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39marray([D\u001b[38;5;241m.\u001b[39mmusic_dls[\u001b[38;5;241m0\u001b[39m]]), device \u001b[38;5;241m=\u001b[39m device)\n\u001b[1;32m      2\u001b[0m predicted_music_2 \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mrender_music(np\u001b[38;5;241m.\u001b[39marray([RIR_2\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()]), np\u001b[38;5;241m.\u001b[39marray([D\u001b[38;5;241m.\u001b[39mmusic_dls[\u001b[38;5;241m0\u001b[39m]]), device \u001b[38;5;241m=\u001b[39m device)\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "predicted_music_1 = evaluate.render_music(np.array([RIR_1.detach().cpu()]), np.array([D.music_dls[0]]), device = device)\n",
    "predicted_music_2 = evaluate.render_music(np.array([RIR_2.detach().cpu()]), np.array([D.music_dls[0]]), device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "\n",
    "duration = predicted_music_1.shape[2]/fs  # Duration in seconds\n",
    "t = np.linspace(0, duration, int(fs * duration), endpoint=False)\n",
    "\n",
    "\n",
    "sd.play(predicted_music_1[0][0], samplerate=48000)\n",
    "sd.wait()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = predicted_music_2.shape[2]/fs \n",
    "t = np.linspace(0, duration, int(fs * duration), endpoint=False)\n",
    "\n",
    "\n",
    "sd.play(predicted_music_2[0][0], samplerate=48000)\n",
    "sd.wait() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(D.music_dls[9][0], samplerate=48000)\n",
    "sd.wait() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
