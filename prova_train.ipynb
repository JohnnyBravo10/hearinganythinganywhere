{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gzanin/.local/lib/python3.11/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import rooms.dataset\n",
    "import render\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import metrics\n",
    "import train\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"prova\"\n",
    "\n",
    "D = rooms.dataset.dataLoader(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training parameters\n",
    "\n",
    "n_fibonacci = 12 #128\n",
    "late_stage_model= \"UniformResidual\" #\"UniformResidual\"\n",
    "toa_perturb = True #True\n",
    "model_transmission = False #False\n",
    "\n",
    "skip_train = False #False\n",
    "continue_train = False #False\n",
    "\n",
    "n_epochs = 3 #1000\n",
    "batch_size = 3 #4\n",
    "lr = 1e-2 #1e-2\n",
    "pink_noise_supervision = False #True\n",
    "pink_start_epoch = 500 #500\n",
    "fs = 4000 #48000\n",
    "\n",
    "load_dir= None\n",
    "save_dir= '~/prova_training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = render.Renderer(n_surfaces=len(D.all_surfaces), n_fibonacci=n_fibonacci,\n",
    "                        late_stage_model=late_stage_model,\n",
    "                        toa_perturb = toa_perturb, model_transmission=model_transmission).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizza piÃ¹ GPU se disponibili\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    R = nn.DataParallel(R).module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directional case\n",
    "loss_fcn = metrics.training_loss_for_learned_bp\n",
    "\n",
    "for listener_position in D.RIRs:\n",
    "    for response in listener_position:\n",
    "        response['t_response'] = torch.Tensor(response['t_response'][:R.RIR_length]) \n",
    "\n",
    "gt_audio = D.RIRs\n",
    "rendering_method = render.Renderer.render_RIR_learned_beampattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(indices, source_xyz, listener_xyzs, surfaces, load_dir):\n",
    "    Ls = []\n",
    "\n",
    "    for idx in indices:\n",
    "        L= render.get_listener(source_xyz=source_xyz, listener_xyz = listener_xyzs[idx], surfaces = surfaces, \n",
    "                               load_dir = load_dir, load_num = idx, speed_of_sound = D.speed_of_sound, \n",
    "                               max_order = D.max_order, parallel_surface_pairs = D.parallel_surface_pairs, \n",
    "                               max_axial_order = D.max_axial_order)\n",
    "        Ls.append(L)\n",
    "    return Ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Considered Paths:\t6\n",
      "Total Considered Paths, after Axial:\t6\n",
      "Valid Paths:\t7\n",
      "Considered Paths:\t6\n",
      "Total Considered Paths, after Axial:\t6\n",
      "Valid Paths:\t7\n",
      "Considered Paths:\t6\n",
      "Total Considered Paths, after Axial:\t6\n",
      "Valid Paths:\t7\n",
      "Considered Paths:\t6\n",
      "Total Considered Paths, after Axial:\t6\n",
      "Valid Paths:\t7\n",
      "Considered Paths:\t6\n",
      "Total Considered Paths, after Axial:\t6\n",
      "Valid Paths:\t7\n",
      "Considered Paths:\t6\n",
      "Total Considered Paths, after Axial:\t6\n",
      "Valid Paths:\t7\n",
      "Considered Paths:\t6\n",
      "Total Considered Paths, after Axial:\t6\n",
      "Valid Paths:\t7\n",
      "Considered Paths:\t6\n",
      "Total Considered Paths, after Axial:\t6\n",
      "Valid Paths:\t7\n",
      "Considered Paths:\t6\n",
      "Total Considered Paths, after Axial:\t6\n",
      "Valid Paths:\t7\n",
      "Loss:\t<function training_loss_for_learned_bp at 0x7cdd383c3ce0>\n",
      "Late Network Style\tUniformResidual\n",
      "energy_vector\n",
      "source_response\n",
      "directivity_sphere\n",
      "decay\n",
      "RIR_residual\n",
      "spline_values\n",
      "bp_ord_cut_freqs\n",
      "0\n",
      "caso direzionale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gzanin/.local/lib/python3.11/site-packages/torch/functional.py:665: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.876358032226562\n",
      "caso direzionale\n",
      "35.86842727661133\n",
      "caso direzionale\n",
      "30.756473541259766\n",
      "caso direzionale\n",
      "26.8070068359375\n",
      "caso direzionale\n",
      "26.84660530090332\n",
      "caso direzionale\n",
      "30.373106002807617\n",
      "caso direzionale\n",
      "27.263751983642578\n",
      "caso direzionale\n",
      "31.742412567138672\n",
      "caso direzionale\n",
      "27.188127517700195\n",
      "1\n",
      "caso direzionale\n",
      "24.68709373474121\n",
      "caso direzionale\n",
      "26.290081024169922\n",
      "caso direzionale\n",
      "30.610441207885742\n",
      "caso direzionale\n",
      "27.635536193847656\n",
      "caso direzionale\n",
      "27.286518096923828\n",
      "caso direzionale\n",
      "24.410873413085938\n",
      "caso direzionale\n",
      "25.81817626953125\n",
      "caso direzionale\n",
      "25.474609375\n",
      "caso direzionale\n",
      "29.56269645690918\n",
      "2\n",
      "caso direzionale\n",
      "26.676376342773438\n",
      "caso direzionale\n",
      "29.150314331054688\n",
      "caso direzionale\n",
      "25.149391174316406\n",
      "caso direzionale\n",
      "23.633041381835938\n",
      "caso direzionale\n",
      "25.358217239379883\n",
      "caso direzionale\n",
      "24.979503631591797\n",
      "caso direzionale\n",
      "26.45018196105957\n",
      "caso direzionale\n",
      "28.499353408813477\n",
      "caso direzionale\n",
      "23.717931747436523\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "if not skip_train:\n",
    "    print(\"Training\")\n",
    "\n",
    "    #Initialize Listeners\n",
    "    Ls = initialize(indices=D.train_indices,\n",
    "                    listener_xyzs=D.xyzs,\n",
    "                    source_xyz=D.speaker_xyz,\n",
    "                    surfaces=D.all_surfaces,\n",
    "                    load_dir=load_dir)\n",
    "            \n",
    "    if continue_train:\n",
    "        R.load_state_dict(torch.load(os.path.join(save_dir,\"weights.pt\"))['model_state_dict'])\n",
    "\n",
    "    losses = train.train_loop(R=R, Ls=Ls, train_gt_audio=gt_audio[D.train_indices], D=D,\n",
    "                        n_epochs = n_epochs, batch_size = batch_size, lr = lr, loss_fcn = loss_fcn,\n",
    "                        save_dir=save_dir,\n",
    "                        pink_noise_supervision = pink_noise_supervision,\n",
    "                        pink_start_epoch=pink_start_epoch,\n",
    "                        continue_train = continue_train, fs=fs)\n",
    "\n",
    "else:\n",
    "    R.load_state_dict(torch.load(os.path.join(save_dir,\"weights.pt\"))['model_state_dict'])\n",
    "    R.train = False\n",
    "    R.toa_perturb = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
